{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from datetime import date, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path = \"../data/train.csv\"\n",
    "# df_train = pd.read_csv(\n",
    "#     train_data_path, usecols=[1, 2, 3, 4, 5], dtype={'onpromotion': bool}, \n",
    "#     converters={'unit_sales': lambda x: np.log1p(float(x)) if float(x) > 0 else 0}, \n",
    "#     parse_dates=['date'], skiprows=range(1, 66458909)\n",
    "# )\n",
    "# df_2017 = df_train[df_train['date'] >= '2017-01-01']\n",
    "\n",
    "df_2017 = pd.read_csv(\"../data/train-2017.csv\", parse_dates=['date'])\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../data/test.csv\", # usecols=[0, 1, 2, 3, 4], \n",
    "    dtype={'onpromotion': bool}, parse_dates=['date']\n",
    ").set_index(['store_nbr', 'item_nbr', 'date'])\n",
    "\n",
    "items = pd.read_csv(\"../data/items.csv\").set_index('item_nbr')\n",
    "\n",
    "stores = pd.read_csv(\"../data/stores.csv\").set_index(\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "items['family'] = encoder.fit_transform(items['family'].values)\n",
    "\n",
    "stores['city'] = encoder.fit_transform(stores['city'].values)\n",
    "stores['state'] = encoder.fit_transform(stores['state'].values)\n",
    "stores['type'] = encoder.fit_transform(stores['type'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个店铺每件商品每天的促销情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promo_2017_train = df_2017.set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date'])[['onpromotion']].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "\n",
    "promo_2017_test = df_test[['onpromotion']].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "\n",
    "del promo_2017_train, promo_2017_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个店铺每件商品每天的销量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_2017.set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date'])[['unit_sales']].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "stores = stores.reindex(df_2017.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每件商品每天的销量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_item = df_2017.groupby('item_nbr')[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每件商品每天的促销情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_item = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个种类的商品在每个店铺每天的销量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017_store_class = df_2017.reset_index()\n",
    "df_2017_store_class['class'] = items['class'].values\n",
    "df_2017_store_class_index = df_2017_store_class[['class', 'store_nbr']]\n",
    "df_2017_store_class = df_2017_store_class.groupby(['class', 'store_nbr'])[df_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个种类的商品在每个店铺每天的促销情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_2017_store_class = promo_2017.reset_index()\n",
    "promo_2017_store_class['class'] = items['class'].values\n",
    "promo_2017_store_class_index = promo_2017_store_class[['class', 'store_nbr']]\n",
    "promo_2017_store_class = promo_2017_store_class.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 特征工程（准备数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, promo_df, t2017, is_train=True, name_prefix=None):\n",
    "    # 促销天数特征（6个特征）\n",
    "    X = {\n",
    "        'promo_14_2017': get_timespan(promo_df, t2017, 14, 14).sum(axis=1).values,  # 前14天中每个店铺商品的促销天数\n",
    "        'promo_60_2017': get_timespan(promo_df, t2017, 60, 60).sum(axis=1).values,  # 前60天中每个店铺商品的促销天数\n",
    "        'promo_140_2017': get_timespan(promo_df, t2017, 140, 140).sum(axis=1).values,  # 前140天中每个店铺商品的促销天数\n",
    "        'promo_3_2017_aft': get_timespan(promo_df, t2017 + timedelta(days=16), 15, 3).sum(axis=1).values,  # 后3天中每个店铺商品的促销天数\n",
    "        'promo_7_2017_aft': get_timespan(promo_df, t2017 + timedelta(days=16), 15, 7).sum(axis=1).values,  # 后7天中每个店铺商品的促销天数\n",
    "        'promo_14_2017_aft': get_timespan(promo_df, t2017 + timedelta(days=16), 15, 14).sum(axis=1).values  # 后14天中每个店铺商品的促销天数\n",
    "    }\n",
    "    \n",
    "    # 促销销量和正常销量特征（24个特征）\n",
    "    for i in [3, 7, 14, 30, 60, 140]:\n",
    "        tmp1 = get_timespan(df, t2017, i, i)  # 前i天每个店铺商品的销量\n",
    "        tmp2 = (get_timespan(promo_df, t2017, i, i) > 0) * 1  # 前i天每个店铺商品的促销情况（是否促销）\n",
    "        \n",
    "        X['has_promo_mean_%s' % i] = (tmp1 * tmp2.replace(0, np.nan)).mean(axis=1).values  # 前i天每个店铺商品平均促销销量\n",
    "        X['has_promo_mean_%s_decay' % i] = (tmp1 * tmp2.replace(0, np.nan) * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values  # 前i天每个店铺商品促销销量和（带衰减）\n",
    "        \n",
    "        X['no_promo_mean_%s' % i] = (tmp1 * (1 - tmp2).replace(0, np.nan)).mean(axis=1).values  # 前i天每个店铺商品正常销量\n",
    "        X['no_promo_mean_%s_decay' % i] = (tmp1 * (1 - tmp2).replace(0, np.nan) * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values  # 前i天每个店铺商品正常销量和（带衰减）\n",
    "        \n",
    "    # 销量统计特征（42个特征）\n",
    "    for i in [3, 7, 14, 30, 60, 140]:\n",
    "        tmp = get_timespan(df, t2017, i, i)  # 前i天每个店铺商品的销量\n",
    "        X['diff_%s_mean' % i] = tmp.diff(axis=1).mean(axis=1).values  # 前i天每个店铺商品销量的平均一阶差分\n",
    "        X['mean_%s_decay' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values  # 前i天每个店铺商品销量的和（带衰减）\n",
    "        X['mean_%s' % i] = tmp.mean(axis=1).values  # 前i天每个店铺商品销量的均值\n",
    "        X['median_%s' % i] = tmp.median(axis=1).values  # 前i天每个店铺商品销量的中位数\n",
    "        X['min_%s' % i] = tmp.min(axis=1).values  # 前i天每个店铺商品销量的最小值\n",
    "        X['max_%s' % i] = tmp.max(axis=1).values  # 前i天每个店铺商品销量的最大值\n",
    "        X['std_%s' % i] = tmp.std(axis=1).values  # 前i天每个店铺商品销量的标准差\n",
    "    \n",
    "    # 销量统计特征2（42个特征）\n",
    "    for i in [3, 7, 14, 30, 60, 140]:\n",
    "        tmp = get_timespan(df, t2017 + timedelta(days=-7), i, i)  # 7天前的前i天每个店铺商品的销量\n",
    "        X['diff_%s_mean_2' % i] = tmp.diff(axis=1).mean(axis=1).values  # 7天前的前i天每个店铺商品销量的平均一阶差分\n",
    "        X['mean_%s_decay_2' % i] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values  # 7天前的前i天每个店铺商品销量的和（带衰减）\n",
    "        X['mean_%s_2' % i] = tmp.mean(axis=1).values  # 7天前的前i天每个店铺商品销量的平均值\n",
    "        X['median_%s_2' % i] = tmp.median(axis=1).values  # 7天前的前i天每个店铺商品销量的中位数\n",
    "        X['min_%s_2' % i] = tmp.min(axis=1).values  # 7天前的前i天每个店铺商品销量的最小值\n",
    "        X['max_%s_2' % i] = tmp.max(axis=1).values  # 7天前的前i天每个店铺商品销量的最大值\n",
    "        X['std_%s_2' % i] = tmp.std(axis=1).values  # 7天前的前i天每个店铺商品销量的标准差\n",
    "        \n",
    "    # 有销量和有促销的天数特征（30个特征）\n",
    "    for i in [7, 14, 30, 60, 140]:\n",
    "        tmp = get_timespan(df, t2017, i, i)  # 前i天每个店铺商品的销量\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values  # 前i天每个店铺商品有销量的天数\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values  # 前i天每个店铺商品距离上一次有销量的天数\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values  # 前i天每个店铺商品距离第一次有销量的天数\n",
    "        \n",
    "        tmp = get_timespan(promo_df, t2017, i, i)  # 前i天每个店铺商品的促销情况\n",
    "        X['has_promo_days_in_last_%s' % i] = (tmp > 0).sum(axis=1).values  # 前i天每个店铺商品有促销的天数\n",
    "        X['last_has_promo_day_in_last_%s' % i] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values  # 前i天每个店铺商品距离上一次有促销的天数\n",
    "        X['first_has_promo_day_in_last_%s' % i] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values  # 前i天每个店铺商品距离第一次有促销的天数\n",
    "        \n",
    "    # 后15天的促销情况特征（3个特征）\n",
    "    tmp = get_timespan(promo_df, t2017 + timedelta(days=16), 15, 15)  # 后15天每个店铺商品的促销情况\n",
    "    X['has_promo_days_in_after_15_days'] = (tmp > 0).sum(axis=1).values  # 后15天每个店铺商品有促销的天数\n",
    "    X['last_has_promo_day_in_after_15_days'] = ((tmp > 0) * np.arange(1, 16)).max(axis=1).values  # 后15天每个店铺商品距离最后一次有促销的天数\n",
    "    X['first_has_promo_day_in_after_15_days'] = 16 - ((tmp > 0) * np.arange(15, 0, -1)).max(axis=1).values  # 后15天每个店铺商品距离最近一次有促销的天数\n",
    "    \n",
    "    # 前15天的销量（15个特征）\n",
    "    for i in range(1, 16):\n",
    "        X['day_%s_2017' % i] = get_timespan(df, t2017, i, 1).values.ravel()\n",
    "    \n",
    "    # 前4（20）周每天的平均销量（14个特征）\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "        \n",
    "    # 前16天到后15天每天的促销情况（32个特征）\n",
    "    for i in range(-16, 16):\n",
    "        X['promo_{}'.format(i)] = promo_df[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "        \n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    if is_train:\n",
    "        y = df[pd.date_range(t2017, periods=16)].values\n",
    "        return X, y\n",
    "    \n",
    "    if name_prefix is not None:\n",
    "        X.columns = ['%s_%s' % (name_prefix, c) for c in X.columns]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preparing training data...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Preparing training data...\")\n",
    "\n",
    "t2017 = date(2017, 6, 14)\n",
    "num_days = 6\n",
    "X_l, y_l = [], []\n",
    "for i in range(num_days):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(df_2017, promo_2017, t2017 + delta)\n",
    "    \n",
    "    X_tmp2 = prepare_dataset(df_2017_item, promo_2017_item, t2017 + delta, is_train=False, name_prefix='item')\n",
    "    X_tmp2.index = df_2017_item.index\n",
    "    X_tmp2 = X_tmp2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "    \n",
    "    X_tmp3 = prepare_dataset(df_2017_store_class, promo_2017_store_class, t2017 + delta, is_train=False, name_prefix='store_class')\n",
    "    X_tmp3.index = df_2017_store_class.index\n",
    "    X_tmp3 = X_tmp3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "    \n",
    "    X_tmp = pd.concat([X_tmp, X_tmp2, X_tmp3, items.reset_index(), stores.reset_index()], axis=1)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "    \n",
    "    del X_tmp, y_tmp, X_tmp2, X_tmp3\n",
    "    gc.collect()\n",
    "\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "\n",
    "del x_l, y_l\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Preparing validation data...\")\n",
    "\n",
    "X_val, y_val = prepare_dateset(df_2017, promo_2017, date(2017, 7, 26))\n",
    "\n",
    "X_val2 = prepare_dateset(df_2017_item, promo_2017, item, date(2017, 7, 26), is_train=False, name_prefix='item')\n",
    "X_val2.index = df_2017_item.index\n",
    "X_val2 = X_val2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "X_val3 = prepare_dateset(df_2017_store_class, df_2017_promo_store_class, date(2017, 7, 26), is_train=False, name_prefix='store_class')\n",
    "X_val3.index = df_2017_store_class.index\n",
    "X_val3 = X_val3.reindex(df_2017_store_class_index).reset_index(drop=True)\n",
    "\n",
    "X_val = pd.concat([X_val, X_val2, X_val3, items.reset_index(), stores.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Preparing testing data...\")\n",
    "\n",
    "X_test = prepare_dateset(df_2017, promo_2017, date(2017, 8, 16), is_train=False)\n",
    "\n",
    "X_test2 = prepare_dateset(df_2017_item, promo_2017_item, date(2017, 8, 16), is_train=False, name_prefix='item')\n",
    "X_test2.index = df_2017_item.index\n",
    "X_test2 = X_test2.reindex(df_2017.index.get_level_values(1)).reset_index(drop=True)\n",
    "\n",
    "X_test3 = prepare_dateset(df_2017_store_class, df_2017_promo_store_class, date(2017, 8, 16), is_train=False, name_prefix='store_class')\n",
    "X_test3.index = df_2017_store_class.index\n",
    "X_test3 = X_test3.reindex(df_2017_store_class_index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
